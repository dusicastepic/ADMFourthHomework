{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading passwords file into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path file passwords2.txt\n",
    "fname = \"C:/Users/sanch/Downloads/passwords2.txt\"\n",
    "# Read and split lines to avoid \\n\n",
    "with open(fname) as f:\n",
    "    content = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OHcv-/U3QI$rdqYTef\"D',\n",
       " 'QtA*.xM$e(+\"aO36r&Uo',\n",
       " \"T;rqw/ou'HN-Pklj6hM*\",\n",
       " 'b%xJ79\"A*C5@ehMfS3lu',\n",
       " 'buI=;LpjBiCm\"JS5\\'#xy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print some results\n",
    "content[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the file passwords2.txt\n",
    "len(content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Proccess file hashing the passwords\n",
    "\"AABA\" = \"AAAB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have define our hashing function converting the string into ASCII values, then ordered them and computing the radix-128 form. At last we do the the division method of hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_code(s, radix, mod):\n",
    "    \"\"\"\n",
    "    Takes a string and apply the division method of hashing to the radix-128 form\n",
    "    h(k) = k % mod\n",
    "    Args:\n",
    "        s (str): String to compute\n",
    "        radix (int): Radix type\n",
    "        mod (int): Number of buckets\n",
    "    Returns: \n",
    "        result (int): Hash result associated from 0 to mod\n",
    "    \"\"\"\n",
    "    pwr = 1\n",
    "    result = 0\n",
    "    list_int_values = [ord(c) for c in s] # Split string and convert each char to ASCII\n",
    "    list_int_values.sort() # Sort the ASCII numbers in the list\n",
    "    for char_ascii in list_int_values: # For every list compute string as natural number radix-128\n",
    "        result += (char_ascii * pwr)\n",
    "        pwr = (pwr * radix)\n",
    "    return result % mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to define the hash table size, we have try some values and observed that the number of collisions decreases with the increase of m. That's the reason of choosing 982451653, that is a prime number and not pow of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 982451653\n"
     ]
    }
   ],
   "source": [
    "# Selecting m for the division method\n",
    "hash_n_buckets = 982451653 \n",
    "print('m:', hash_n_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step we compute our hash function with radix 128 and the mod defined before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash every password\n",
    "list_hashed = []\n",
    "for password in content:\n",
    "    list_hashed.append( hash_code(s=password, radix=128, mod=hash_n_buckets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[923467939, 199890044, 54920260, 942237609, 129453431]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_hashed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95073099"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list_hashed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have **110M** values and **95,073,099 are unique**. So we have only **14,926,901 collisions** that could be false positives or duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the list into a file\n",
    "with open('passwords_hashed_prime_high.csv', 'w') as f:\n",
    "    for item in list_hashed:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding duplicates or false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list_hashed obtained before\n",
    "fname = \"passwords_hashed_prime_high.csv\"\n",
    "with open(fname) as f:\n",
    "    list_hashed = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string list to int list\n",
    "list_hashed = list(map(int, list_hashed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are making a list with the index pointing to the collisions found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_collision = []\n",
    "def list_collision(seq):\n",
    "    seen = set()\n",
    "    for idx, item in enumerate(seq):\n",
    "        if item in seen:\n",
    "            index_collision.append(idx)\n",
    "        else: \n",
    "            seen.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_collision(list_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14926901"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the list into a file\n",
    "with open('index_dup_high.csv', 'w') as f:\n",
    "    for item in index_collision:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the index_collision obtained before\n",
    "fname = \"index_dup_high.csv\"\n",
    "with open(fname) as f:\n",
    "    index_collision = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string list to int list\n",
    "index_collision = list(map(int, index_collision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14926901"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_collision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made a function to count the number of false positives and duplicates as we can see, the thing is that takes to long to compute \"list.index\" so we aren't able to run all the execution, we have done only 1000 values example and as we can see it takes 9,325 (s). A possible solution could be to use a default dic instead of using list.index to find the index but with our computers we are not able to compute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp 1000 d 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.325398504064879"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def count_d_fd():\n",
    "    duplicates_count = 0\n",
    "    false_duplicates_count = 0\n",
    "    for value_index_coll in index_collision[0:1000]:\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "        value_index_orig = list_hashed.index(list_hashed[value_index_coll]) # Obtain the first index with the same hash value\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "        content_coll = ''.join(sorted(content[value_index_coll]))\n",
    "        content_set = ''.join(sorted(content[value_index_orig]))\n",
    "        if content_coll == content_set:\n",
    "            duplicates_count += 1\n",
    "        else:\n",
    "            false_duplicates_count += 1\n",
    "    print(\"fp\", false_duplicates_count, \"d\", duplicates_count)\n",
    "        \n",
    "timeit.timeit(count_d_fd, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, taking into account that we have 10M duplicates as it says the statement in our case we have **14926901 collisions**:\n",
    "- 10M duplicates \n",
    "- 4926901 false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Proccess file hashing the passwords\n",
    "\"AABA\" != \"AAAB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we don't have to order the data as we have done before but it is almost the same function and the same proccess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_code2(s, radix, mod):\n",
    "    \"\"\"\n",
    "    Takes a string and apply the division method of hashing to the radix-128 form\n",
    "    h(k) = k % mod\n",
    "    Args:\n",
    "        s (str): String to compute\n",
    "        radix (int): Radix type\n",
    "        mod (int): Number of buckets\n",
    "    Returns: \n",
    "        result (int): Hash result associated from 0 to mod\n",
    "    \"\"\"\n",
    "    pwr = 1\n",
    "    result = 0\n",
    "    list_int_values = [ord(c) for c in s] # Split string and convert each char to ASCII\n",
    "    for char_ascii in list_int_values: # For every list compute string as natural number radix-128\n",
    "        result += (char_ascii * pwr)\n",
    "        pwr = (pwr * radix)\n",
    "    return result % mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 982451653\n"
     ]
    }
   ],
   "source": [
    "# Selecting m for the division method\n",
    "hash_n_buckets = 982451653 \n",
    "print('m:', hash_n_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash every password\n",
    "list_hashed = []\n",
    "for password in content:\n",
    "    list_hashed.append( hash_code2(s=password, radix=128, mod=hash_n_buckets) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
