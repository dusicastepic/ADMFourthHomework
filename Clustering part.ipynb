{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After web scrapping we created one single data frame with columns 'price', 'locali', 'superficie', 'bagni', 'piano', 'description' and stored it as a .csv file for future usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'locali', 'superficie', 'bagni', 'piano', 'description'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data into memory from the stored .csv file\n",
    "data = pd.read_csv(\"data_houses.csv\", sep='\\t', encoding='utf-8')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23203, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of rows before cleaning\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price             1\n",
       "locali          354\n",
       "superficie       24\n",
       "bagni           491\n",
       "piano          3793\n",
       "description    5045\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values of the dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price          object\n",
       "locali         object\n",
       "superficie     object\n",
       "bagni          object\n",
       "piano          object\n",
       "description    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking data types of the dataset\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>locali</th>\n",
       "      <th>superficie</th>\n",
       "      <th>bagni</th>\n",
       "      <th>piano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23202</td>\n",
       "      <td>22849</td>\n",
       "      <td>23179</td>\n",
       "      <td>22712</td>\n",
       "      <td>19410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2335</td>\n",
       "      <td>6</td>\n",
       "      <td>587</td>\n",
       "      <td>315</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>€ 199.000</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>338</td>\n",
       "      <td>7177</td>\n",
       "      <td>962</td>\n",
       "      <td>10007</td>\n",
       "      <td>4236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            price locali superficie  bagni  piano\n",
       "count       23202  22849      23179  22712  19410\n",
       "unique       2335      6        587    315     15\n",
       "top     € 199.000     3          90     1       1\n",
       "freq          338   7177        962  10007   4236"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,['price','locali','superficie','bagni','piano']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The values where the number of bathrooms are 1, 2 or 3 should be kept because they are the most common ones and other numbers \n",
    "#are rare and therefore considered outliers(they are probably buildings_?)\n",
    "#also 3+ is eliminated cause it has ambigious meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      3265\n",
       "2      2563\n",
       "T      2285\n",
       "3      1904\n",
       "A      1275\n",
       "4      1216\n",
       "R       843\n",
       "5       716\n",
       "6       374\n",
       "S       289\n",
       "7       271\n",
       "8       104\n",
       "9        22\n",
       "11+      19\n",
       "10        8\n",
       "Name: piano, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We decided to drop the rows where the value of the floor is 11+ because there aren't many of those rows and they don't show\n",
    "data.piano.value_counts()\n",
    "#eliminate R, A, S and 11+  cause it is ambigious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After _analyzing_ the possible values of each attribute of the dataset we decided the following about the process of \n",
    "**cleaning** the dataset before making two separate datasets for clustering.\n",
    "    \n",
    "The data cleaning process:\n",
    "    1. Remove nan values\n",
    "    2. Attribute price should be converted to integer data type and '€' removed from the values\n",
    "    3. In attribute locali remove rows where the value of locali is 5+ and convert attribute to integer data type\n",
    "    4. Attribute superficie has some strange values because of the scrapping, like dates '14/02/19' '18/01/19' and all the values that don't make sense should be removed and the attribute should be converted to the integer data type\n",
    "    5. For attribute piano replace T->0 and drop the rows with piano values A, R, S and 11+ cause they are ambiguous\n",
    "    \n",
    "The goal of the cleaning process was to eliminate all the ambiguous values and categorical values that can't have a meaningful numerical representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Method that removes nan values and cleanes the data\n",
    "    \n",
    "    Input: dataframe\n",
    "    Output: cleaned dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    #Remove rows where there aren't all values present\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    #convert to int price and remove € \n",
    "    for i in data.index:\n",
    "    #Becasuse of the web scrapping some prices had strings and text in this waz we dealt with it\n",
    "        try:\n",
    "            data.price[i]=int(data.price[i].replace('€', '').strip().replace('.','').replace('da',''))\n",
    "    #before word class there is price we need\n",
    "        except:\n",
    "            try:\n",
    "                data.price[i]=int(data.price[i].split('class')[0].replace('€', '').strip().replace('.',''))\n",
    "           #in case of the bad scrapping value (e.g.just text) just drop those rows\n",
    "            except:\n",
    "                data.drop(i,inplace=True)\n",
    "            \n",
    "    #convert to int superficie\n",
    "    data.superficie=data.superficie.replace('[/]', '', regex=True).apply(lambda x: int(str(x).replace('.','')))\n",
    "    #Drop rows where values of locali is 5+ and convert to int\n",
    "    data['locali']=data['locali'].apply(lambda x: x.strip())\n",
    "    data.drop(data[ data['locali']=='5+'].index,inplace=True)\n",
    "#    data.locali=data.locali.apply(lambda x:int(x))\n",
    "\n",
    "\n",
    "    #Attribute piano replace T->0 drop A, R, S and 11+  cause it is ambigious \n",
    "    data.drop(data[(data['piano']=='A') | (data['piano']=='R') | ( data['piano']=='S')| ( data['piano']=='11+')].index,inplace=True)\n",
    "    #convert to int and piano T is 'terro' which means it is floor 0\n",
    "    data['piano']=np.where(data['piano']=='T', 0, data['piano'])     \n",
    "    \n",
    "\n",
    "#    data.piano=data.piano.apply(lambda x: int(x))\n",
    "    data.bagni=data.bagni.apply(lambda x: x.strip())\n",
    "    data.drop(data[( data['bagni']!='1')&( data['bagni']!='2')&( data['bagni']!='3')].index,inplace=True)    \n",
    "#    data.bagni=data.bagni.apply(lambda x: int(x))\n",
    "#\n",
    "    data[[\"price\",\"locali\",\"piano\", \"bagni\"]] = data[[\"price\",\"locali\",\"piano\", \"bagni\"]].apply(pd.to_numeric)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10773, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The number of rows after cleaning the dataset\n",
    "#10773\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price          0\n",
       "locali         0\n",
       "superficie     0\n",
       "bagni          0\n",
       "piano          0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After cleaning the data(dropping rows where there aren't some values) there aren't any NaN values present\n",
    "cleaned_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price           int64\n",
       "locali          int64\n",
       "superficie      int64\n",
       "bagni           int64\n",
       "piano           int64\n",
       "description    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the single data frame we extracted using the web scrapping process we created the Description and the Information datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Description dataset)\n",
    "\n",
    "    columns: description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>papillo eur\\r\\r\\n                                PAPILLO EUR in elegante complesso residenziale rifinitissimo bilocale composto da soggiorno con angolo cottura, stanza da letto bagno e ampio balcone . con Rifiniture di pregio, pavimenti in parquet / grees, infissi in legno con vetro camera e porte in noce, grate nel salone, riscaldamento termoautonomo con caldaia centralizzata, aria condizionata, videocitofono, porta blindata, serramenti elettrici con chiusura centralizzata, antenna satellitare, isolamento termo acustico, pannelli solari e fotovoltaici , rilevatori elettronici di gas. Tutte le camere sono fornite di impianto antifurto, presa antenna satellitare e presa telefonica.div\\r\\r\\ndiv\\r\\r\\nORARI lunedi chiusidiv\\r\\r\\n martedi 10:00-17:00div\\r\\r\\n mercoledi 10:00-17:00div\\r\\r\\ndivgiovedi 10:00-17:00div\\r\\r\\ndivvenrdi 10:00-17:00div\\r\\r\\ndivsabato 10:00-17:00div\\r\\r\\n domenica 10:00-13:00\\r\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     description\n",
       "1  papillo eur\\r\\r\\n                                PAPILLO EUR in elegante complesso residenziale rifinitissimo bilocale composto da soggiorno con angolo cottura, stanza da letto bagno e ampio balcone . con Rifiniture di pregio, pavimenti in parquet / grees, infissi in legno con vetro camera e porte in noce, grate nel salone, riscaldamento termoautonomo con caldaia centralizzata, aria condizionata, videocitofono, porta blindata, serramenti elettrici con chiusura centralizzata, antenna satellitare, isolamento termo acustico, pannelli solari e fotovoltaici , rilevatori elettronici di gas. Tutte le camere sono fornite di impianto antifurto, presa antenna satellitare e presa telefonica.div\\r\\r\\ndiv\\r\\r\\nORARI lunedi chiusidiv\\r\\r\\n martedi 10:00-17:00div\\r\\r\\n mercoledi 10:00-17:00div\\r\\r\\ndivgiovedi 10:00-17:00div\\r\\r\\ndivvenrdi 10:00-17:00div\\r\\r\\ndivsabato 10:00-17:00div\\r\\r\\n domenica 10:00-13:00\\r\\r\\n            "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_dataset=pd.DataFrame(cleaned_data.description)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "description_dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Information dataset)\n",
    "\n",
    "    columns: price, locali, superficie, bagni, piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>locali</th>\n",
       "      <th>superficie</th>\n",
       "      <th>bagni</th>\n",
       "      <th>piano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225000</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>339000</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>480000</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>135000</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>249000</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  locali  superficie  bagni  piano\n",
       "1  225000  2       50          1      1    \n",
       "5  339000  3       90          1      4    \n",
       "6  480000  4       125         2      4    \n",
       "7  135000  2       60          1      5    \n",
       "8  249000  2       75          1      1    "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_dataset=cleaned_data.drop(['description'],axis=1)\n",
    "information_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save information and description datasets to two separate .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf(df,vocabulary):\n",
    "    \"\"\"\n",
    "    method that computes an inverted index\n",
    "    \n",
    "    input:  airbnbdata-just for using the number of files we made\n",
    "            inverted_idx(dictionary, key=term_id, value=list of document_ids)\n",
    "            vocabulary(dictionary of all unique words, key=term, value=term_id)\n",
    "    output: tf_idf_dic(dictionary of tf_idf_values for all docs, key=tuple(term,doc_id ), value=tf_idf value)\n",
    "    \"\"\"\n",
    "    tf_idf_dic=dict()\n",
    "    #total number of documents\n",
    "    total_num_docs=df.shape[0]\n",
    "    result_df=pd.DataFrame()\n",
    " #use apply\n",
    "#for i in df.index:\n",
    "        #preprocessing \n",
    "        df=df.description[i]\n",
    "        filtered_words=preprocessing_text(df)\n",
    "        tf_series=pd.Series(filtered_words)\n",
    "        #series of tf values\n",
    "        tf_series=((tf_series.value_counts())/len(tf_series)).sort_index()\n",
    "        idf_series=pd.Series(list(set(filtered_words))).sort_values()\n",
    "        #idf calculation\n",
    "        idf_calc=idf_series.apply(lambda x: np.log(total_num_docs/len(inverted_idx[vocabulary[x]])))\n",
    "        #combine tf and idf in one result_df dataframe\n",
    "        result_df=pd.concat([pd.Series(idf_series.values),pd.Series(tf_series.values),pd.Series(idf_calc.values)],axis=1)#.reset_index()\n",
    "        #multiply tf and idf and create tf_idf column\n",
    "        result_df['tf_idf']=result_df[1]*result_df[2]\n",
    "        #key=tuple(term,doc_id), value=tf_idf value\n",
    "        for idx in range(result_df.shape[0]):\n",
    "            tf_idf_dic[result_df[0][idx],i]=result_df['tf_idf'][idx]\n",
    "    return tf_idf_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "every row is a separate house(which is considered as a separate document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(data):\n",
    "    \"\"\"\n",
    "    Method that creates vocabulary\n",
    "    \n",
    "    Input: dataframe in order to access number of files made by that airbnb dataframe\n",
    "    Output: vocabulary list and doc_vocabs(dictionary, key='doc_id',value=list of unique words belonging to that document)\n",
    "    \"\"\"  \n",
    "    #list for vocabulary \n",
    "    vocabulary_lst=[]\n",
    "    #preprocessing description and title\n",
    "    df=df.description[0]+' '+df.title[0]\n",
    "    filtered_words=preprocessing_text(df)\n",
    "    #temporary variable set used for making vocabulary with unique words\n",
    "    temp_vocabulary_set=set()\n",
    "    for word in filtered_words:\n",
    "        temp_vocabulary_set.add(word)\n",
    "        vocabulary_lst.append(temp_vocabulary_set)\n",
    "        doc_vocabs[i]=list(temp_vocabulary_set)\n",
    "    #union of content of vocabulary_lst\n",
    "    vocabulary_set=set.union(*vocabulary_lst)\n",
    "    #mapping words into integers\n",
    "    vocabulary={} \n",
    "    for k,v in enumerate(vocabulary_set):\n",
    "        vocabulary[v]= k\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_text(df):\n",
    "    \"\"\"\n",
    "    Method that returns filtered words from the text input \n",
    "    \n",
    "    Input: string(text)\n",
    "    Output: list(bag of words)\n",
    "    \"\"\"  \n",
    "    #remove upper cases\n",
    "    df=df.lower()\n",
    "   \n",
    "    #replacing new line sign '\\n' '\\r' and 'div' from html with a whitespace ' '    \n",
    "    df=df.replace('\\\\n',' ').replace('\\\\r',' ').replace('div',' ')\n",
    "    \n",
    "    #for removing stop words\n",
    "    stop_words = set(stopwords.words('italian')) \n",
    "    stop_words.add('div')\n",
    "    stop_words.add('n')\n",
    "    stop_words.add('b')\n",
    "\n",
    "    #remove numbers\n",
    "    df = re.sub(\"\\d+\", \"\", df)\n",
    "    \n",
    "    #for removing punctuations\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    #to tokenize the string\n",
    "    word_tokens = tokenizer.tokenize(df)     \n",
    "\n",
    "    #stemming\n",
    "    ps = PorterStemmer()\n",
    "    filtered_words = [ps.stem(w) for w in word_tokens if not w in stop_words] \n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "This step consists in _clustering the house announcements_ using **K-means++** and choosing the **optimal** number of clusters using the **Elbow-Method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should we normalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
